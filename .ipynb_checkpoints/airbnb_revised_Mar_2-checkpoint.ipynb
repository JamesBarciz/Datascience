{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "92O-J9K9I-13"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split, validation_curve\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import category_encoders as ce\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "\n",
    "# In order to see all of the columns of the dataset we need to set the display options\n",
    "# from the Pandas package to at least 100 (the dataset has 96 columns) and, for the rows,\n",
    "# I set it to at least 100 which will help when I check for null values and dtypes.\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None) # Everytime I made a new column I would have a warning raised\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWMuEo-UI-1-"
   },
   "outputs": [],
   "source": [
    "# Importing the CSV 'listings_summary.csv' from the Kaggle dataset found at this\n",
    "# URL: https://www.kaggle.com/brittabettendorf/berlin-airbnb-data\n",
    "\n",
    "listings_summary = pd.read_csv('https://raw.githubusercontent.com/BuildWeekAirbnbOptimal2/Datascience/master/Berlin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "uF5N9hUFI-2D",
    "outputId": "855c2061-d77f-41d7-9ea4-442732cc97c2"
   },
   "outputs": [],
   "source": [
    "# As stated above, there are 96 columns and over 20,000 observations\n",
    "\n",
    "listings_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Y7B0JP7_I-2I",
    "outputId": "31623bf3-0124-46d4-cf93-02afd14aa1b9"
   },
   "outputs": [],
   "source": [
    "# Checking the dtypes of the dataset...\n",
    "\n",
    "# The goal of this project is to find the optimal price for an AirBnB in Belin, Germany so,\n",
    "# the target variable will be the 'price' which is currently an object and therefore, will\n",
    "# have to be dealt with appropriately.\n",
    "\n",
    "listings_summary.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pO0Bo1oDI-2M",
    "outputId": "5a301e48-b3bd-4cb9-a8b2-34003b0767cc"
   },
   "outputs": [],
   "source": [
    "# Next we will check for the null values within the dataset - there are quite a few...\n",
    "\n",
    "listings_summary.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "LnhJr1aPI-2Q",
    "outputId": "298a6c73-37aa-45ae-c0b9-659f7a553427"
   },
   "outputs": [],
   "source": [
    "# Calling the head of the dataset to visualize what the first row of observations looks like\n",
    "\n",
    "listings_summary.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_summary['neighbourhood_cleansed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qLjDA1dEI-2U"
   },
   "outputs": [],
   "source": [
    "# We can already tell later on we will have to drop a few columns where the cardinality for some\n",
    "# object features, while finite, will be very high epecially in the case of URLs, names, reviews,\n",
    "# descriptions, etc. so we will remove a few of them now and possibly later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "j-LG5uTeI-2Y",
    "outputId": "f0ebb0f3-f73f-49ea-ef0b-104d40f174b0"
   },
   "outputs": [],
   "source": [
    "# First, we will use a for loop to check the number of unique values in each column.  This is acheived\n",
    "# by taking the length of the value_counts of a column.\n",
    "\n",
    "for col in listings_summary:\n",
    "    print(f'There are/is {len(listings_summary[col].value_counts())} unique value(s) for column: {col}') if listings_summary[col].dtypes=='O' else print(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "fYrC8g-QI-2b",
    "outputId": "7ee30477-b4a0-4f7a-f977-4b0929e65d16"
   },
   "outputs": [],
   "source": [
    "listings_summary.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ND4mo69tI-2e"
   },
   "outputs": [],
   "source": [
    "# The first thing we will do is remove the object columns with high cardinality and features that are probably\n",
    "# redundant like 'city' since this is the Berlin AirBnB dataset - 'zipcode' may be useful but neighbourhood could\n",
    "# cover that.\n",
    "\n",
    "high_cardin = ['listing_url', 'name', 'summary', 'space', 'description', 'experiences_offered', 'neighborhood_overview',\n",
    "               'notes', 'transit', 'access', 'interaction', 'house_rules', 'thumbnail_url', 'medium_url',\n",
    "               'picture_url', 'xl_picture_url', 'host_url', 'host_name', 'host_about', 'host_thumbnail_url',\n",
    "               'host_picture_url', 'host_verifications', 'street', 'city', 'state', 'zipcode', 'market',\n",
    "               'smart_location', 'country_code', 'country', 'bed_type', 'amenities', 'weekly_price', 'monthly_price',\n",
    "               'has_availability', 'calendar_last_scraped', 'requires_license', 'license', 'is_business_travel_ready',\n",
    "               'require_guest_profile_picture', 'require_guest_phone_verification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CRV8gcp9I-2i"
   },
   "outputs": [],
   "source": [
    "listings_df = listings_summary.drop(columns=high_cardin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 985
    },
    "colab_type": "code",
    "id": "A_43oL4II-2m",
    "outputId": "7c549d7c-68be-4859-ad6c-573c3d50ea9d"
   },
   "outputs": [],
   "source": [
    "listings_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lw0Hx1ZKI-2p"
   },
   "outputs": [],
   "source": [
    "# We will also remove columns that have many NaN values\n",
    "\n",
    "high_na = ['host_response_time', 'host_response_rate', 'host_acceptance_rate', 'square_feet', 'jurisdiction_names']\n",
    "\n",
    "Berlin_airbnb = listings_df.drop(columns=high_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "colab_type": "code",
    "id": "sXWJOOiDI-2u",
    "outputId": "687d4f42-6095-423a-8f7a-4843456571b0"
   },
   "outputs": [],
   "source": [
    "Berlin_airbnb.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yBMvU63lI-2x"
   },
   "outputs": [],
   "source": [
    "# Next we will engineer some features based on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8vhYXw5bI-21"
   },
   "outputs": [],
   "source": [
    "# Originally, the 'security_deposit' column would've been kept and replaced NaN values with the mean but,\n",
    "# Since there are many NaN values we will make a binary feature stating '1' if they require a security deposit\n",
    "# and '0' if the do not require one.\n",
    "\n",
    "\n",
    "# TODO: drop Berlin_airbnb['security_deposit']\n",
    "has_security_dep = []\n",
    "for i in Berlin_airbnb['security_deposit']:\n",
    "    if i==np.NaN:\n",
    "        has_security_dep.append(0)\n",
    "    else:\n",
    "        has_security_dep.append(1)\n",
    "Berlin_airbnb['require_security_deposit'] = np.array(has_security_dep).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xrIaWPgGI-24"
   },
   "outputs": [],
   "source": [
    "# We will do the same with cleaning fee and call it 'has_cleaning_service'...\n",
    "\n",
    "# TODO: drop Berlin_airbnb['cleaning_fee']\n",
    "has_cleaning = []\n",
    "for i in Berlin_airbnb['cleaning_fee']:\n",
    "    if i==np.NaN:\n",
    "        has_cleaning.append(0)\n",
    "    else:\n",
    "        has_cleaning.append(1)\n",
    "Berlin_airbnb['has_cleaning_service'] = np.array(has_cleaning).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SgHBQcbBI-27"
   },
   "outputs": [],
   "source": [
    "# Possible columns to impute or use for feature engineering\n",
    "\n",
    "# review_scores_rating - mode = 100.00 (46 unique values between 50.00 and 100.00)\n",
    "# review_scores_accuracy - mode = 10.0 (more than 50% of the data)\n",
    "# review_scores_cleanliness - mode = 10.0\n",
    "# review_scores_checkin - mode = 10.0 (more than 50% of the data)\n",
    "# review_scores_communication - mode = 10.0 (more than 50% of the data)\n",
    "# review_scores_location - mode = 10.0\n",
    "# review_scores_value - mode = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "K-8mgCyoI-2-",
    "outputId": "a29222f7-c272-45f6-fc9d-1b1a725072ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300\n"
     ]
    }
   ],
   "source": [
    "# Next, we will get rid of the dollar signs and any commas that may be contained in the 'price'\n",
    "# and 'extra_people' column by making a function that will strip the dollar sign ('$') from the\n",
    "# array, remove the redundant '.00', and then remove commas for amounts 1000 or larger\n",
    "\n",
    "def dollar_to_int(row):\n",
    "    return row.strip('$')[:-3]\n",
    "def no_comma(row):\n",
    "    return row.replace(',','')\n",
    "\n",
    "# To show it works...\n",
    "\n",
    "amount = dollar_to_int('$1,300.00')\n",
    "print(no_comma(amount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "twMMCI5_I-3A"
   },
   "outputs": [],
   "source": [
    "# Applying them to the dataset...\n",
    "\n",
    "Berlin_airbnb['price'] = Berlin_airbnb['price'].apply(dollar_to_int).apply(no_comma).astype(int)\n",
    "Berlin_airbnb['extra_people'] = Berlin_airbnb['extra_people'].apply(dollar_to_int).apply(no_comma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0ZIyggKuI-3D",
    "outputId": "b6886e6a-9610-4c50-8fcf-60281dfcf45f"
   },
   "outputs": [],
   "source": [
    "Berlin_airbnb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PM7Wcuo8I-3H"
   },
   "outputs": [],
   "source": [
    "Berlin_airbnb = Berlin_airbnb.drop(columns=['security_deposit', 'cleaning_fee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vZKt5jcKI-3L"
   },
   "outputs": [],
   "source": [
    "# 'property_type', 'room_type', 'accommodates','bathrooms', 'bedrooms', 'beds', 'bed_type','price','number_of_reviews',('review_scores_value '),'instant_bookable','cancellation_policy','neighbourhood','host_identity_verified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cOLXPpfvI-3P"
   },
   "outputs": [],
   "source": [
    "# Possibly useful: - Predicting 'PRICE'\n",
    "# 1. neighbourhood\n",
    "# 2. property type\n",
    "# 3. room type\n",
    "# 4. accommodates\n",
    "# 5. bathrooms\n",
    "# 6. bedrooms\n",
    "# 7. beds\n",
    "# 8. reviews_scores_value\n",
    "# 9. instant_bookable\n",
    "# 10. cancellation_policy\n",
    "# 10. has_cleaning_service\n",
    "\n",
    "### Columns we may go with\n",
    "# 'property_type', 'room_type', 'accommodates','bathrooms', 'bedrooms', 'beds', 'bed_type','price','number_of_reviews',('review_scores_value '),'instant_bookable','cancellation_policy','neighbourhood','host_identity_verified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "SLc7ZmZVI-3S",
    "outputId": "4698cb96-51fe-4a23-de6f-14a6d7080d75"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>price</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>host_identity_verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Guesthouse</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60</td>\n",
       "      <td>118</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>strict_14_with_grace_period</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>flexible</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90</td>\n",
       "      <td>143</td>\n",
       "      <td>9.0</td>\n",
       "      <td>t</td>\n",
       "      <td>strict_14_with_grace_period</td>\n",
       "      <td>Prenzlauer Berg</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>strict_14_with_grace_period</td>\n",
       "      <td>Schöneberg</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42</td>\n",
       "      <td>197</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Prenzlauer Berg</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  property_type        room_type  accommodates  bathrooms  bedrooms  beds  \\\n",
       "0    Guesthouse  Entire home/apt             3        1.0       1.0   2.0   \n",
       "1     Apartment     Private room             2        1.0       1.0   1.0   \n",
       "2     Apartment  Entire home/apt             4        1.0       1.0   2.0   \n",
       "3     Apartment     Private room             2        1.0       1.0   1.0   \n",
       "4     Apartment     Private room             2        1.0       1.0   2.0   \n",
       "\n",
       "   price  number_of_reviews  review_scores_value instant_bookable  \\\n",
       "0     60                118                  9.0                f   \n",
       "1     17                  6                 10.0                f   \n",
       "2     90                143                  9.0                t   \n",
       "3     26                 25                  9.0                f   \n",
       "4     42                197                  9.0                f   \n",
       "\n",
       "           cancellation_policy    neighbourhood host_identity_verified  \n",
       "0  strict_14_with_grace_period            Mitte                      t  \n",
       "1                     flexible              NaN                      t  \n",
       "2  strict_14_with_grace_period  Prenzlauer Berg                      t  \n",
       "3  strict_14_with_grace_period       Schöneberg                      t  \n",
       "4                     moderate  Prenzlauer Berg                      t  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Berlin_subset = Berlin_airbnb[['property_type', 'room_type', 'accommodates', 'bathrooms', 'bedrooms', 'beds',\n",
    "                               'price', 'number_of_reviews', 'review_scores_value', 'instant_bookable',\n",
    "                               'cancellation_policy', 'neighbourhood', 'host_identity_verified']]\n",
    "Berlin_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r95hu8ugI-3V"
   },
   "outputs": [],
   "source": [
    "###### We need to include why we are using these columns!! ######\n",
    "\n",
    "# i.e. Why we chose to condense 'accommodates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "colab_type": "code",
    "id": "HtGGD_-NI-3Z",
    "outputId": "0a134e6e-0edf-425d-8308-d438a81426ff"
   },
   "outputs": [],
   "source": [
    "Berlin_subset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "d2INBQWzI-3b",
    "outputId": "11dedadc-620b-4195-f958-d92e7bb47df6"
   },
   "outputs": [],
   "source": [
    "Berlin_subset['accommodates'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "wD4od-onI-3e",
    "outputId": "5beb4bf0-042c-4eb1-d7ae-caabcd224c9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1', '2', '3', '4', '5', '6', '7+'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minimizing the values for the accommodates column\n",
    "# We will make them objects from 1-6 and then 7+\n",
    "\n",
    "accommodate = []\n",
    "for int in Berlin_subset['accommodates']:\n",
    "    if int==1:\n",
    "        accommodate.append('1')\n",
    "    elif int==2:\n",
    "        accommodate.append('2')\n",
    "    elif int==3:\n",
    "        accommodate.append('3')\n",
    "    elif int==4:\n",
    "        accommodate.append('4')\n",
    "    elif int==5:\n",
    "        accommodate.append('5')\n",
    "    elif int==6:\n",
    "        accommodate.append('6')\n",
    "    elif int>=7:\n",
    "        accommodate.append('7+')\n",
    "    else:\n",
    "        accommodate.append('')\n",
    "set(accommodate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "RtHBEzDbI-3l",
    "outputId": "4e392a49-f84a-4ac6-ee5c-fb0ea38dcb94"
   },
   "outputs": [],
   "source": [
    "Berlin_subset['can_accommodate'] = np.array(accommodate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "mq5Np0tNI-3o",
    "outputId": "58df0504-c053-4f72-f4e3-5fc59ca1d8bb"
   },
   "outputs": [],
   "source": [
    "bedrooms = []\n",
    "for bed in Berlin_subset['bedrooms']:\n",
    "    if bed==1.0:\n",
    "        bedrooms.append('1')\n",
    "    else:\n",
    "        bedrooms.append('2+')\n",
    "set(bedrooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "Xty0gVezI-3r",
    "outputId": "4d75d6a5-a2bb-479a-fd80-18181b2c22a3"
   },
   "outputs": [],
   "source": [
    "Berlin_subset['n_bedrooms'] = np.array(bedrooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WVMEGMfrI-3u",
    "outputId": "e53460d0-6a3f-4ebf-f00d-87d3e87d6734"
   },
   "outputs": [],
   "source": [
    "bathrooms = []\n",
    "for bath in Berlin_subset['bathrooms']:\n",
    "    if bath==1.0:\n",
    "        bathrooms.append('1')\n",
    "    else:\n",
    "        bathrooms.append('2+')\n",
    "set(bathrooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "eCdAtQHfI-3x",
    "outputId": "844d2b82-3265-4140-d19b-1b79262ae1bb"
   },
   "outputs": [],
   "source": [
    "Berlin_subset['n_bathrooms'] = np.array(bathrooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9_LR1D2JI-30",
    "outputId": "1c9b338e-b3a9-465f-a6c5-506daf0721ab"
   },
   "outputs": [],
   "source": [
    "beds = []\n",
    "for bed in Berlin_subset['beds']:\n",
    "    if bed==1.0:\n",
    "        beds.append('1')\n",
    "    else:\n",
    "        beds.append('2+')\n",
    "set(beds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "D-BZUxb4I-33",
    "outputId": "1617556e-751c-4ad4-cb21-fa1ead853026"
   },
   "outputs": [],
   "source": [
    "Berlin_subset['n_beds'] = np.array(beds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZO8GdBJTI-36"
   },
   "outputs": [],
   "source": [
    "def to_nbool(array):\n",
    "    for i in array:\n",
    "        if i=='t':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "FEe6nJFtI-38",
    "outputId": "5391ca52-f8bc-4ddb-d8f9-e7e714d2a3f6"
   },
   "outputs": [],
   "source": [
    "Berlin_subset['host_identity_verified'] = Berlin_subset['host_identity_verified'].dropna().apply(to_nbool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "jeZHJ2arI-3_",
    "outputId": "bf4de6dd-c7f5-4cef-a8a3-d3b7170b4707"
   },
   "outputs": [],
   "source": [
    "Berlin_subset['instant_bookable'] = Berlin_subset['instant_bookable'].dropna().apply(to_nbool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "l-Kcuj0EI-4C",
    "outputId": "f565019a-8369-4811-84d3-9d0633e5d965"
   },
   "outputs": [],
   "source": [
    "Berlin_subset['review_scores_value'] = Berlin_subset['review_scores_value'].replace(np.NaN, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "I3Kp1--AI-4F",
    "outputId": "c2ab6763-a175-4c11-dd61-961e5d6441e6"
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for rating in Berlin_subset['review_scores_value']:\n",
    "    if rating>=7.0:\n",
    "        scores.append(rating)\n",
    "    else:\n",
    "        scores.append(0.0)\n",
    "set(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "pIkZmXVdI-4I",
    "outputId": "8c07b8b9-5901-4d64-89d9-0617000856b4"
   },
   "outputs": [],
   "source": [
    "Berlin_subset['review_score'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z1ODuJ56I-4L"
   },
   "outputs": [],
   "source": [
    "Berlin = Berlin_subset.drop(columns=['review_scores_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6tMFTWcMI-4N",
    "outputId": "beb3610d-aa4c-49a9-a839-bd55c6835f19"
   },
   "outputs": [],
   "source": [
    "Berlin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "vYoWIuPfI-4R",
    "outputId": "c2cb608d-779e-43e2-92fc-fbe641118fca"
   },
   "outputs": [],
   "source": [
    "Berlin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Berlin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-7b4fcc7cee04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Instead of reassigning these values to 'cancellation_policy' we will keep the original just in case we need it back\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mBerlin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cancel_policy'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBerlin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cancellation_policy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'super_strict_30'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'super_strict_60'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'strict_14_with_grace_period'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'strict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Berlin' is not defined"
     ]
    }
   ],
   "source": [
    "# Instead of reassigning these values to 'cancellation_policy' we will keep the original just in case we need it back\n",
    "\n",
    "Berlin['cancel_policy'] = Berlin['cancellation_policy'].replace(('super_strict_30', 'super_strict_60', 'strict_14_with_grace_period'),'strict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "c3g74IFVa0G7",
    "outputId": "8f1733b7-44d7-4b7a-c418-f944f48c4c60"
   },
   "outputs": [],
   "source": [
    "len(Berlin.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "colab_type": "code",
    "id": "ChDrWEX_ctUL",
    "outputId": "4bff0930-62e4-4721-d6a8-fb70aab0271f"
   },
   "outputs": [],
   "source": [
    "Berlin.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Berlin['neighbourhood'] = Berlin['neighbourhood'].replace(np.NaN, 'TODO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Berlin['neighbourhood'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something we could do is split these neighbourhoods into North, South, East, and West Berlin.\n",
    "# There are also 12 boroughs in Berlin that could be used.\n",
    "# All in the name of Data Science........\n",
    "\n",
    "boroughs = []\n",
    "for boro in Berlin[''room_type', 'instant_bookable', 'boroughs',\n",
    "            'can_accommodate', 'n_bedrooms', 'n_bathrooms', 'n_beds',\n",
    "            'cancel_policy'']:\n",
    "    \n",
    "    Charlot = ['Charlottenburg-Nord', 'Schmargendorf', 'Grunewald', 'Halensee', 'Westend', 'Wilmersdorf', 'Charlottenburg']\n",
    "    Fried = ['Kreuzberg', 'Friedrichshain']\n",
    "    Licht = ['Falkenberg', 'Neu-Hohenschönhausen', 'Alt-Hohenschönhausen', 'Karlshorst', 'Fennpfuhl', 'Friedrichsfelde',\n",
    "             'Lichtenberg', 'Rummelsburg']\n",
    "    Marzahn = ['Kaulsdorf', 'Hellersdorf', 'Mahlsdorf', 'Biesdorf', 'Marzahn']\n",
    "    Mitte = ['Hansaviertel', 'Potsdamer Platz', 'Tiergarten', 'Moabit', 'Wedding', 'Mitte']\n",
    "    Neukolln = ['Gropuisstadt', 'Buckow', 'Rudow', 'Britz', 'Neukölln']\n",
    "    Pankow = ['Rosenthal', 'Wilhelmsruh', 'Blankenburg', 'Heinersdorf', 'Buch', 'Karow', 'Französisch Buchholz',\n",
    "              'Niederschönhausen', 'Weißensee', 'Pankow', 'Prenzlauer Berg']\n",
    "    Reinick = ['Lübars', 'Konradshöhe', 'Waidmannslust', 'Märkisches Viertel', 'Heiligesee', 'Hermsdorf', 'Frohnau',\n",
    "               'Wittenau', 'Tegel', 'Reinickendorf']\n",
    "    Spandau = ['Haselhorst', 'Gatow', 'Falkenhagener', 'Siemensstadt', 'Staaken', 'Hakenfelde', 'Kladow',\n",
    "               'Wilhelmstadt', 'Spandau']\n",
    "    Steglitz = ['Wansee', 'Dahlem', 'Nikolassee', 'Lankwitz', 'Zehlendorf', 'Lichterfelde', 'Steglitz']\n",
    "    Tempelhof = ['Marienfelde', 'Lichtenrade', 'Mariendorf', 'Friedenau', 'Tempelhof', 'Schöneberg']\n",
    "    Treptow = ['Müggelheim', 'Bohnsdorf', 'Grünau', 'Schmökewite', 'Niederschöneweide', 'Altglienicke',\n",
    "               'Johannesthal', 'Friedrichshagen', 'Adlershof', 'Rahnsdorf', 'Oberschöneweide',\n",
    "               'Köpenick', 'Plänterwald', 'Baumschulenweg', 'Alt-Treptow']\n",
    "    \n",
    "    if boro in Charlot:\n",
    "        boroughs.append('Charlottenburg-Wilmersdorf')\n",
    "    elif boro in Fried:\n",
    "        boroughs.append('Friedrichshain-Kreuzberg')\n",
    "    elif boro in Licht:\n",
    "        boroughs.append('Lichtenberg')\n",
    "    elif boro in Marzahn:\n",
    "        boroughs.append('Marzahn-Hellersdorf')\n",
    "    elif boro in Mitte:\n",
    "        boroughs.append('Mitte')\n",
    "    elif boro in Neukolln:\n",
    "        boroughs.append('Neukölln')\n",
    "    elif boro in Pankow:\n",
    "        boroughs.append('Pankow')\n",
    "    elif boro in Reinick:\n",
    "        boroughs.append('Reinickendorf')\n",
    "    elif boro in Spandau:\n",
    "        boroughs.append('Spandau')\n",
    "    elif boro in Steglitz:\n",
    "        boroughs.append('Steglitz-Zehlendorf')\n",
    "    elif boro in Tempelhof:\n",
    "        boroughs.append('Tempelhof-Schöneberg')\n",
    "    elif boro in Treptow:\n",
    "        boroughs.append('Treptow-Köpernick')\n",
    "    else:\n",
    "        boroughs.append('TODO')\n",
    "set(boroughs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Berlin['boroughs'] = boroughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Berlin['boroughs'] = Berlin['boroughs'].replace('TODO', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Berlin['host_identity_verified'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 'host_identity_verified', it would make sense to fill the NA values with 0 (FALSE)\n",
    "# We will also convert the column from float to integers(int64)\n",
    "\n",
    "Berlin['host_identity_verified'] = Berlin['host_identity_verified'].replace(np.NaN, 0).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving this column for backup\n",
    "\n",
    "Berlin_cancel = Berlin['cancellation_policy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Berlin.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassigning the Berlin dataframe to the columns we are checking out\n",
    "#  'neighbourhood',\n",
    "\n",
    "Berlin = Berlin[['property_type', 'room_type', 'price', 'cancellation_policy',\n",
    "                 'instant_bookable', 'neighbourhood', 'host_identity_verified',\n",
    "                 'accommodates', 'bedrooms', 'bathrooms', 'beds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Berlin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "property_type              0\n",
       "room_type                  0\n",
       "price                      0\n",
       "cancellation_policy        0\n",
       "instant_bookable           0\n",
       "neighbourhood              0\n",
       "host_identity_verified     0\n",
       "accommodates               0\n",
       "bedrooms                  18\n",
       "bathrooms                 32\n",
       "beds                      40\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Berlin.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22552, 11)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_na = Berlin[Berlin[['bedrooms', 'bathrooms', 'beds']].notna()]\n",
    "non_na.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_na.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_na['property_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = []\n",
    "for prop_type in non_na['property_type']:\n",
    "    if prop_type=='Apartment' or prop_type=='Serviced apartment':\n",
    "        prop.append('Apartment')\n",
    "    else:\n",
    "        prop.append('Non-apartment')\n",
    "set(prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_na['Property_type'] = prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_na['Property_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_na['room_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_na['host_identity_verified'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_na['can_accommodate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_na['n_bedrooms'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_na['n_bathrooms'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_na['n_beds'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_na['cancel_policy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_na['price'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_na.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 157 observations (of 19k) with a price above $300\n",
    "non_na[(non_na['price']>300)]['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 11)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_na_new = non_na[non_na['price']<=300]\n",
    "non_na_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=0.8, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-36511e75597f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# **If we have time, we may want to try different values for test_size**\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnon_na_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.80\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.80\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2098\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2099\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[1;32m-> 2100\u001b[1;33m                                               default_test_size=0.25)\n\u001b[0m\u001b[0;32m   2101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   1780\u001b[0m             \u001b[1;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1781\u001b[0m             'aforementioned parameters.'.format(n_samples, test_size,\n\u001b[1;32m-> 1782\u001b[1;33m                                                 train_size)\n\u001b[0m\u001b[0;32m   1783\u001b[0m         )\n\u001b[0;32m   1784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=0.8, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# Ofer work starting here (James' notes between two asterisks **)\n",
    "\n",
    "# Create Train/**Val/**Test **Incorporating random_state for reproducibility**\n",
    "# **If we have time, we may want to try different values for test_size**\n",
    "\n",
    "train, test = train_test_split(non_na_new, train_size=0.80, test_size=0.20, random_state=42)\n",
    "train, val = train_test_split(train, train_size=0.80, test_size=0.20, random_state=42)\n",
    "\n",
    "for df in train, val, test:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Splitting up features and target then, X_train, y_train, etc.**\n",
    "# 'neighbourhood',\n",
    "\n",
    "features = ['room_type', 'instant_bookable', 'boroughs',\n",
    "            'can_accommodate', 'n_bedrooms', 'n_bathrooms', 'n_beds',\n",
    "            'cancel_policy']\n",
    "target = 'price'\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_val = val[features]\n",
    "y_val = val[target]\n",
    "X_test = test[features]\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Taking a baseline using 0 features and the mean of the target('price') column**\n",
    "# How far off would we be if we used this average?\n",
    "\n",
    "# Arrange y target vectors - target already assigned in cell above\n",
    "y_train_mae = train[target]\n",
    "y_val_mae = val[target]\n",
    "y_test_mae = test[target]\n",
    "\n",
    "print(f'Mean Baseline (using 0 features) and Price mean of: {round(y_train_mae.mean())}')\n",
    "guess = round(y_train.mean()) # **so that the mean is an integer**\n",
    "\n",
    "# Train Error\n",
    "y_pred = [guess] * len(y_train_mae)\n",
    "mae = mean_absolute_error(y_train_mae, y_pred)\n",
    "print(f'Train Error for Berlin: ${mae:.2f}')\n",
    "\n",
    "# Validate Error\n",
    "y_pred = [guess] * len(y_val_mae)\n",
    "mae = mean_absolute_error(y_val_mae, y_pred)\n",
    "print(f'Train Error for Berlin: ${mae:.2f}')\n",
    "\n",
    "# Test Error\n",
    "y_pred = [guess] * len(y_test_mae)\n",
    "mae = mean_absolute_error(y_test_mae, y_pred)\n",
    "print(f'Test Error for Berlin: ${mae:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the categorical features using Ordinal Encoder which will start at 1\n",
    "# for the first unique string and then count +1 for each new unique string\n",
    "\n",
    "encoder = ce.OrdinalEncoder()\n",
    "\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "X_val_encoded = encoder.fit_transform(X_val)\n",
    "X_test_encoded = encoder.fit_transform(X_test)\n",
    "\n",
    "# To see what we did...\n",
    "X_train_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now check the data types...\n",
    "X_train_encoded.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Making a function which will test the numeric features indivudually using LinearRegression**\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "def lr_feature_error(array):\n",
    "    \n",
    "    # Arranging X features matrices (already did y target vectors)\n",
    "    X_train_lr = X_train_encoded[array].values.reshape(-1, 1)\n",
    "    print(f'Linear Regression, dependent on: {array}')\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train_lr, y_train)\n",
    "    y_pred = model.predict(X_train_lr)\n",
    "    mae = mean_absolute_error(y_train, y_pred)\n",
    "    print(f'Train Error: {mae:.2f} percentage points \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train_encoded:\n",
    "    lr_feature_error(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Getting the intercepts**\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Intercepts and coefficients\n",
    "print('Intercept', model.intercept_)\n",
    "coefficients = pd.Series(model.coef_, features)\n",
    "print(coefficients.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting these coefficients\n",
    "coefficients = pd.Series(model.coef_, X_train_encoded.columns)\n",
    "plt.figure(figsize=(5,10))\n",
    "coefficients.sort_values().plot.barh(color='grey');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **TL:DR  - Mainly for originally numeric columns**\n",
    "# **For the Positive features, as the feature increases, so does the Price**\n",
    "# **For the Negative features, as the feature decreases, so does the Price**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying some ordinal encoding and LinearRegression() through a pipeline (sklearn.pipeline.make_pipeline)\n",
    "# Ordinal Encoder will take string values, start at 1 and then count up for each new unique value\n",
    "# After that we will standardize the data so they can be comparable\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(),\n",
    "    StandardScaler(),\n",
    "    LinearRegression()\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # The code below will get coefficients for LinearRegression()\n",
    "\n",
    "lr = pipeline.named_steps['linearregression']\n",
    "importances_lr = pd.Series(lr.coef_, X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the scaled coefficients\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature Importance')\n",
    "importances_lr.sort_values().plot.barh(color='grey');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try a RandomForestRegressor!\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(),\n",
    "    StandardScaler(),\n",
    "    RandomForestRegressor(n_jobs=-1, n_estimators=100, random_state=42)\n",
    ")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "rf = pipeline.named_steps['randomforestregressor']\n",
    "importances = pd.Series(rf.feature_importances_, X_train.columns)\n",
    "\n",
    "# Plot feature importances\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature Importance')\n",
    "importances.sort_values().plot.barh(color='grey');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on train, score on test\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_pred_val = pipeline.predict(X_val)\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "\n",
    "rf = pipeline.named_steps['randomforestregressor']\n",
    "\n",
    "# Print Results\n",
    "print('Training R^2', pipeline.score(X_train, y_train))\n",
    "print(f'Training MAE: {mean_absolute_error(y_train, y_pred_train)} dollars')\n",
    "print('Validation R^2', pipeline.score(X_val, y_val))\n",
    "print(f'Validation MAE: {mean_absolute_error(y_val, y_pred_val)} dollars')\n",
    "print('Test R^2', pipeline.score(X_test, y_test))\n",
    "print(f'Test MAE: {mean_absolute_error(y_test, y_pred_test)} dollars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross_val_score with SelectKBest\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(),\n",
    "    StandardScaler(),\n",
    "    SelectKBest(f_regression, k='all'),\n",
    "    Ridge()\n",
    ")\n",
    "\n",
    "k = 3\n",
    "scores = cross_val_score(pipeline, X_train, y_train, cv=k,\n",
    "                          scoring='neg_mean_absolute_error')\n",
    "print(f'MAE for {k} folds:', -scores)\n",
    "print('Mean score', -scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With RandomForestRegressor - The MAE is lower when using TargetEncoder\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "#     ce.OrdinalEncoder(),\n",
    "    ce.TargetEncoder(min_samples_leaf=1, smoothing=1),\n",
    "#     StandardScaler(),\n",
    "    RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42)\n",
    ")\n",
    "\n",
    "k = 3\n",
    "scores = cross_val_score(pipeline, X_train, y_train, cv=k,\n",
    "                          scoring='neg_mean_absolute_error')\n",
    "print(f'MAE for {k} folds:', -scores)\n",
    "print('Mean score', -scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomized Search with multiple parameter distributions\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.TargetEncoder(),\n",
    "    RandomForestRegressor()\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    'targetencoder__min_samples_leaf': stats.randint(1, 1000),\n",
    "    'targetencoder__min_samples_leaf': stats.uniform(1, 1000),\n",
    "    'randomforestregressor__n_estimators': stats.randint(50, 500),\n",
    "    'randomforestregressor__max_depth': [5, 10, 15, 20, None],\n",
    "    'randomforestregressor__max_features': stats.uniform(0,1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    verbose=10,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best hyperparameters:', search.best_params_)\n",
    "print('Cross-Validation MAE:', -search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Results\n",
    "pd.DataFrame(search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_val = val[features]\n",
    "y_val = val[target]\n",
    "X_test = test[features]\n",
    "y_test = test[target]\n",
    "\n",
    "y_pred = pipeline.predict(X_train)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print(f'Train R^2 Score: {pipeline.score(X_train, y_train)}')\n",
    "print(f'Train MAE: ${mae:,.0f}')\n",
    "\n",
    "y_pred = pipeline.predict(X_val)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "print(f'Val R^2 Score: {pipeline.score(X_val, y_val)}')\n",
    "print(f'Val MAE: ${mae:,.0f}')\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Test R^2 Score: {pipeline.score(X_test, y_test)}')\n",
    "print(f'Test MAE: ${mae:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNeighborsRegressor\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.TargetEncoder(),\n",
    "    KNeighborsRegressor(n_neighbors=8,n_jobs=-1)\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_train)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print(f'Train R^2 Score: {pipeline.score(X_train, y_train)}')\n",
    "print(f'Train MAE: ${mae:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ce.TargetEncoder(min_samples_leaf=1, smoothing=1),\n",
    "    KNeighborsRegressor()\n",
    ")\n",
    "\n",
    "n_neighbors = range(1, 30, 1)\n",
    "train_scores, val_scores = validation_curve(\n",
    "    pipeline, X_train, y_train,\n",
    "    param_name='kneighborsregressor__n_neighbors',\n",
    "    param_range=n_neighbors,\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.plot(n_neighbors, np.mean(train_scores, axis=1), color='blue', label='training error')\n",
    "plt.plot(n_neighbors, np.mean(val_scores, axis=1), color='red', label='validation error')\n",
    "plt.title('Validation Curve')\n",
    "plt.xlabel('model complexity KNeighborsRegressor n_neighbors')\n",
    "plt.ylabel('model score: R^2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    ce.TargetEncoder(),\n",
    "    KNeighborsRegressor()\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    'targetencoder__min_samples_leaf': stats.randint(1, 1000),\n",
    "    'targetencoder__min_samples_leaf': stats.uniform(1, 1000),\n",
    "    'kneighborsregressor__n_neighbors': range(1, 50, 1),\n",
    "    'kneighborsregressor__leaf_size': range(1, 50, 1),\n",
    "    'kneighborsregressor__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'kneighborsregressor__weights': ['uniform', 'distance']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=10,\n",
    "    cv=5,\n",
    "    verbose=10,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best hyperparameters \"KNeighborsRegressor\":', search.best_params_)\n",
    "print('Cross-Validation R^2:', search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_val = val[features]\n",
    "y_val = val[target]\n",
    "X_test = test[features]\n",
    "y_test = test[target]\n",
    "\n",
    "y_pred = pipeline.predict(X_train)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print(f'Train R^2 Score: {pipeline.score(X_train, y_train)}')\n",
    "print(f'Train MAE: ${mae:,.0f}')\n",
    "\n",
    "y_pred = pipeline.predict(X_val)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "print(f'Val R^2 Score: {pipeline.score(X_val, y_val)}')\n",
    "print(f'Val MAE: ${mae:,.0f}')\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Test R^2 Score: {pipeline.score(X_test, y_test)}')\n",
    "print(f'Test MAE: ${mae:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "knr = pipeline.named_steps['kneighborsregressor']\n",
    "importances = pd.Series(knr.kneighbors, X_train.columns)\n",
    "importances\n",
    "knr.kneighbors_graph\n",
    "# # Plot feature importances\n",
    "# %matplotlib inline\n",
    "\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.title('Feature Importance')\n",
    "# importances.sort_values().plot.barh(color='grey');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TOPPNgOzdVjZ",
    "outputId": "66b35f39-fde8-456a-be75-7aa1d3d80f83"
   },
   "outputs": [],
   "source": [
    "#stripping NaN values\n",
    "berlin_na_stripped = cancel_policy\n",
    "berlin_na_stripped.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7okBlQ0nevLG"
   },
   "outputs": [],
   "source": [
    "Berlin = berlin_na_stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Oxq-TNo5I-4V",
    "outputId": "82ab8bcd-7f07-41a8-9dc6-e5d9763785cc"
   },
   "outputs": [],
   "source": [
    "#Ofer starts here, continues on above work by James\n",
    "#Create Train/Test split:\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# create training and testing vars\n",
    "\n",
    "X = Berlin.drop(columns='price')\n",
    "y = Berlin.price\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "id": "TB_j4WcNfeqd",
    "outputId": "265b1565-747c-43fb-f582-14efc36e4ab6"
   },
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "rf = pipeline.named_steps['randomforestregressor']\n",
    "importances = pd.Series(rf.feature_importances_, X_train.columns)\n",
    "\n",
    "# Plot feature importances\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature Importance')\n",
    "importances.sort_values().plot.barh(color='grey');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "id": "aVMNUVL9hslE",
    "outputId": "8aa128ef-bfe2-40da-bb01-56180bb26528"
   },
   "outputs": [],
   "source": [
    "#try to graph it out\n",
    "import plotly.express as px\n",
    "px.scatter(Berlin, x='neighbourhood', y= target)\n",
    "#this shows pricey neighbourhoods from left to right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "id": "XwV2xl5Gixzm",
    "outputId": "e3f9015c-abe5-4b41-cf08-116ab21c71e5"
   },
   "outputs": [],
   "source": [
    "#try to graph it out\n",
    "import plotly.express as px\n",
    "px.scatter(Berlin, x='number_of_reviews', y= target)\n",
    "#this shows the less reviews, the higher the price (this probably suggests that highly priced properties don't get booked much)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "IJlbL-tPieVP",
    "outputId": "c99b5e76-22da-4c3b-b7d9-5e6de619c682"
   },
   "outputs": [],
   "source": [
    "#try to graph it out\n",
    "import seaborn as sns\n",
    "sns.boxplot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aXJXrZfklKyI"
   },
   "outputs": [],
   "source": [
    "#throw some shapley values\n",
    "# !pip install shap\n",
    "# import shap\n",
    "\n",
    "# X_train_encoded = encoder.transform(X_train)\n",
    "# row = X_train_encoded\n",
    "\n",
    "# explainer = shap.TreeExplainer(rf)\n",
    "# shap_values = explainer.shap_values(row)\n",
    "\n",
    "# shap.initjs()\n",
    "# shap.force_plot(\n",
    "# # shap.summary_plot( \n",
    "#     base_value=explainer.expected_value,\n",
    "#     shap_values=shap_values,\n",
    "#     features=row\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "colab_type": "code",
    "id": "c9yHXjqOp56x",
    "outputId": "4adc537f-542a-47a2-c979-a9d5d099d4de"
   },
   "outputs": [],
   "source": [
    "# # Feature Scaling\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "colab_type": "code",
    "id": "zstAoQ7gYzme",
    "outputId": "722d2b85-4a39-4e57-83b6-99397eebb9f6"
   },
   "outputs": [],
   "source": [
    "# Arrange data into X features matrix and y target vector\n",
    "target = 'price'\n",
    "\n",
    "!pip install --upgrade category_encoders\n",
    "import category_encoders as ce\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    # SimpleImputer(strategy='median'), \n",
    "    RandomForestRegressor(n_estimators=250, random_state=42, n_jobs=-1)\n",
    ")\n",
    "\n",
    "# Fit on train, score on test\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "\n",
    "rf = pipeline.named_steps['randomforestregressor']\n",
    "encoder = pipeline.named_steps['ordinalencoder']\n",
    "\n",
    "\n",
    "# Print Results\n",
    "print('Training R^2', pipeline.score(X_train, y_train))\n",
    "print(f'Training MAE: {mean_absolute_error(y_train, y_pred_train)} dollars')\n",
    "print('Validation R^2', pipeline.score(X_test, y_test))\n",
    "print(f'Validation MAE: {mean_absolute_error(y_test, y_pred_test)} dollars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "colab_type": "code",
    "id": "WXpTqjA4t88K",
    "outputId": "d72a37cb-c4d3-44ff-b466-d88c880d1c8e"
   },
   "outputs": [],
   "source": [
    "X_test.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "S2H58mlqnEE3",
    "outputId": "16423746-54f3-46c3-b255-01ce63534ec6"
   },
   "outputs": [],
   "source": [
    "\n",
    "#I think this is predicting the first 4 rows prices? so, $32, $31, $113.9, $67 ?\n",
    "#Can someone verify this? :)\n",
    "y_pred = pipeline.predict(X_test[:3])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "SN3SD9q_wMQQ",
    "outputId": "9f3e1fd6-c02b-4b17-e727-cd5733e781af"
   },
   "outputs": [],
   "source": [
    "#looking up the first 4 prices of y\n",
    "y_test.head(4)\n",
    "#So wait - I thought this was a 1 dimensional array\n",
    "#what is the number on the left? on the right it's the price correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XOV-jOcfw3-B"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "airbnb_berlin_notebook (Ofer update Fri 28 Feb).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
